{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cek.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Q6SaLl90t26M",
        "3mWW5IWe54xP"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3HrrzL2CWhh"
      },
      "source": [
        "# Prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW3Fvw9yNoeg",
        "outputId": "db8f1df2-5cf0-484d-8677-35c394b1863b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGFZXRRVCcJB"
      },
      "source": [
        "#Copy model.h5 & tokenizer\n",
        "!cp '/content/drive/My Drive/Machine Learning/Quora/bi_quora_question_pairs.h5' '/content/' #Mengambil model.h5 dari proses sebelumnya\n",
        "!cp '/content/drive/My Drive/Machine Learning/Quora/tokenizer.pkl' '/content/' #Mengambil tokenizer dari proses sebelumnya"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjqQUXLqyzu3"
      },
      "source": [
        "# Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRkiPkoB8-H9"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak-p_B6FucKj"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from nltk import word_tokenize\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "import time\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('popular')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('indonesian'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ic71vyJCGnp"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIuzunbUudIX",
        "outputId": "76f0e5ce-2a01-4e1d-80fb-15d91565f5eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with open('tokenizer.pkl', 'rb') as handle:\n",
        "\ttokenizer = pickle.load(handle)\n",
        "\n",
        "def clean_question(question):\n",
        "\ttokens = word_tokenize(question)\n",
        "\ttokens = [t for t in tokens if t.isalpha()]\n",
        "\ttokens = ' '.join(tokens)\n",
        "\treturn tokens\n",
        "\n",
        "def process_question(question):\n",
        "\tclean_q = []\n",
        "\tfor q in question:\n",
        "\t\tq = str(q)\n",
        "\t\tq = clean_question(q)\n",
        "\t\tclean_q.append(q)\n",
        "\treturn clean_q\n",
        "\n",
        "def make_prediction(model_path, data):\n",
        "\tmodel = load_model(model_path)\n",
        "\ty_pred = model.predict(data)\n",
        "\n",
        "\treturn y_pred\n",
        "\n",
        "\n",
        "def tokenize_pad_questions(question_1, question_2):\n",
        "\tquestion_1 = process_question(question_1)\n",
        "\tquestion_2 = process_question(question_2)\n",
        "\n",
        "\tquestion1_word_sequence = tokenizer.texts_to_sequences(question_1)\n",
        "\tquestion2_word_sequence = tokenizer.texts_to_sequences(question_2)\n",
        "\n",
        "\tq1_data = pad_sequences(question1_word_sequence, maxlen = 30, padding = 'post')\n",
        "\tq2_data = pad_sequences(question2_word_sequence, maxlen = 30, padding = 'post')\n",
        "\n",
        "\treturn q1_data, q2_data\n",
        "\n",
        "\n",
        "def clean_results(result):\n",
        "\tif np.round(result) == 1:\n",
        "\t\treturn 'Pertanyaan Duplikat'\n",
        "\telse: \n",
        "\t\treturn 'Pertanyaan Berbeda'\t\n",
        "\n",
        "first_question = []\n",
        "second_question = []\n",
        "\n",
        "#Contoh Tabel 4.2 pertanyaan 1 dan 2 yang ingin dibandingkan\n",
        "question_1 = \"Apa yang harus diperhatikan sebelum membeli keyboard komputer\"\n",
        "question_2 = \"Apa saja perlu dipertimbangkan sebelum membeli keyboard komputer\"\n",
        "\n",
        "first_question.append(question_1)\n",
        "second_question.append(question_2)\n",
        "\n",
        "q1_data, q2_data = tokenize_pad_questions(first_question, second_question)\n",
        "y_pred = make_prediction('bi_quora_question_pairs.h5', [q1_data, q2_data])\n",
        "y_pred_clean = clean_results(y_pred)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 50) for input Tensor(\"input_1:0\", shape=(None, 50), dtype=float32), but it was called on an input with incompatible shape (None, 30).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 50) for input Tensor(\"input_2:0\", shape=(None, 50), dtype=float32), but it was called on an input with incompatible shape (None, 30).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyeO11Y-vIO3",
        "outputId": "57ff01e6-de93-4140-9504-20150162a961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"Dua pertanyaan tersebut hasilnya: *{y_pred_clean}* dengan {np.round(y_pred[0][0].astype(float),2)*100}% probability\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dua pertanyaan tersebut hasilnya: *Pertanyaan Duplikat* dengan 98.0% probability\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SeJ_4H2dIwf",
        "outputId": "7d70717a-93c8-4265-b269-1d72f3dd8e14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9783343]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6SaLl90t26M"
      },
      "source": [
        "# Streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mWW5IWe54xP"
      },
      "source": [
        "## Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25xzgzuj59X0"
      },
      "source": [
        "%%writefile config.py\n",
        "\n",
        "FILE_DIR = '/content/'\n",
        "MODEL = 'bi_quora_question_pairs.h5'\n",
        "TOKENIZER = 'tokenizer.pkl'\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 20\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1STzsGE6B-O"
      },
      "source": [
        "%%writefile process.py\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('popular')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop=set(stopwords.words('indonesian'))\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "def clean_question(question):\n",
        "\ttokens = word_tokenize(question)\n",
        "\ttokens = [t for t in tokens if t.isalpha()]\n",
        "\ttokens = ' '.join(tokens)\n",
        "\treturn tokens\n",
        "\n",
        "\n",
        "\n",
        "def process_question(question):\n",
        "\tclean_q = []\n",
        "\tfor q in question:\n",
        "\t\tq = str(q)\n",
        "\t\tq = clean_question(q)\n",
        "\t\tclean_q.append(q)\n",
        "\treturn clean_q\n",
        "\n",
        "\n",
        "\n",
        "def make_prediction(model_path, data):\n",
        "\tmodel = load_model(model_path)\n",
        "\ty_pred = model.predict(data)\n",
        "\n",
        "\treturn y_pred\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZEIPJos6Q7d"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import config\n",
        "from process import process_question, clean_question, make_prediction\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(config.FILE_DIR + config.TOKENIZER, 'rb') as handle:\n",
        "\ttokenizer = pickle.load(handle)\n",
        "\n",
        "\n",
        "def tokenize_pad_questions(question_1, question_2):\n",
        "\tquestion_1 = process_question(question_1)\n",
        "\tquestion_2 = process_question(question_2)\n",
        "\n",
        "\tquestion1_word_sequence = tokenizer.texts_to_sequences(question_1)\n",
        "\tquestion2_word_sequence = tokenizer.texts_to_sequences(question_2)\n",
        "\n",
        "\tq1_data = pad_sequences(question1_word_sequence, maxlen = config.MAX_SEQUENCE_LENGTH, padding = 'post')\n",
        "\tq2_data = pad_sequences(question2_word_sequence, maxlen = config.MAX_SEQUENCE_LENGTH, padding = 'post')\n",
        "\n",
        "\treturn q1_data, q2_data\n",
        "\n",
        "\n",
        "def clean_results(result):\n",
        "\n",
        "\tif np.round(result) == 1:\n",
        "\t\treturn 'Pertanyaan Duplikat'\n",
        "\telse: \n",
        "\t\treturn 'Pertanyaan Berbeda'\t\n",
        "\n",
        "\n",
        "\n",
        "def run():\n",
        "\tfirst_question = []\n",
        "\tsecond_question = []\n",
        "\n",
        "\tst.title('Identifikasi Duplikat Pertanyaan')\n",
        "\tst.text('')\n",
        "\tst.subheader('Deskripsi')\n",
        "\tst.markdown('Dengan lebih dari 100 juta orang mengunjungi Quora setiap bulan, banyak orang mengajukan pertanyaan serupa. Menggunakan GloVe + BiLSTM untuk mengidentifikasi pertanyaan-pertanyaan ini secara akurat akan membantu pengguna menemukan jawaban dengan lebih efektif dan efisien.')\n",
        "\tst.text('')\n",
        "\n",
        "\tquestion_1 = st.text_input('Apa pertanyaan pertama Anda?')\n",
        "\tquestion_2 = st.text_input('Apa pertanyaan kedua Anda?')\n",
        "\n",
        "\tfirst_question.append(question_1)\n",
        "\tsecond_question.append(question_2)\n",
        "\n",
        "\tif st.button('Predict'):\n",
        "\t\twith st.spinner('Sedang mengidentifikasi pertanyaan...'):\n",
        "\t\t\tif question_1 is not '' and question_2 is not '':\n",
        "\t\t\t\tq1_data, q2_data = tokenize_pad_questions(first_question, second_question)\n",
        "\t\t\t\ty_pred = make_prediction(config.FILE_DIR + config.MODEL, [q1_data, q2_data])\n",
        "\t\t\t\ty_pred_clean = clean_results(y_pred)\n",
        "\t\t\telse:\n",
        "\t\t\t\tst.write('[INFO] Tidak ada pertanyaan.. Silahkan tulis pertanyaan')\n",
        "\n",
        "\n",
        "\t\t\tst.success(f\"Dua pertanyaan tersebut hasilnya: **{y_pred_clean}** dengan **{np.round(y_pred[0][0].astype(float),2)*100}%** probability\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\trun()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5Szs4Ks6bnY"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnVrCjTwaAOP"
      },
      "source": [
        "!pip install streamlit\n",
        "!pip install ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grhjFsoQVIhG"
      },
      "source": [
        "!streamlit run app.py &>/dev/null&"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7vsD043cwQH"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -qq ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwuujlPcdWT_"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "  \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ8jewGreYvD"
      },
      "source": [
        "!streamlit run app.py"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}